<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Stanford University CS422: Interactive and Embodied Learning</title>

  <!-- bootstrap -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css">

  <!-- Google fonts -->
  <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" type="text/css" href="style.css" />

 </head>

 <div id="header">
  <div class='text-right'><h2><a href="index.html" style="color: black; text-decoration: none;">CS422: Interactive and Embodied Learning</a></h2>
</div>

  <h1>Syllabus and readings</h1>
  <div class='text-center'>
    <p>Required readings in <b>bold</b>; others supplementary. As an alternative to covering the one or two assigned papers, presenters should feel free to present on the general topic domain using the primary and supplementary readings (or even suggest their own!). The supplementary lists can get quite long -- this is not meant to be imposing! We simply think that each represents a handy constellation of papers for those interested in getting more acquainted with each subarea. We will provide a roadmap as we go with overviews in class. Feel free to ask for more context at any time.
    </p>

    <p>
      Please see <a href="talk_faq.html">these guidelines</a> for giving a good talk. Every student is responsible for doing all required readings. Please come prepared to discuss, and come being able to describe background, methodology, experimental setups, and key results (for experimental papers). For non-experimental papers, be prepared to discuss the background and each key idea.

    </p>
  </div>

<div class="sechighlight">
<div class="container sec">
<h2>Framing</h2>
<h3>Class 1 (Jan 8): Conceptual framing, logistics.</h3>
<h3>Class 2 (Jan 10): An early relevant on curiosity and world model building (instructor presents to model presentations).</h3>
<b><a href="https://ieeexplore.ieee.org/document/4141061" target="_blank" rel="noopener noreferrer">Intrinsic Motivation Systems for Autonomous Mental Development</a></b><br>
Supplementary:<br>
<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2017.02124/full" target="_blank" rel="noopener noreferrer">A Developmental Approach to Machine Learning?</a><br>
<a href="https://psycnet.apa.org/fulltext/2017-42390-001.html" target="_blank" rel="noopener noreferrer">From Needs to Goals and Representations: Foundations for a Unified Theory of Motivation, Personality, and Development</a><br>
<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-7687.2007.00569.x" target="_blank" rel="noopener noreferrer">Core Knowledge</a><br>
<h3>Class 3 (Jan 17): Introduction: open-ended learning, autotelic agents, and curiosity (Instructor lecture). Projects discussion.</h3>
<b><a href="https://arxiv.org/abs/1802.07442" target="_blank" rel="noopener noreferrer">Learning to Play with Intrinsically-Motivated Self-Aware Agents</a></b><br>
<b><a href="https://arxiv.org/abs/2007.07853" target="_blank" rel="noopener noreferrer">Active World Model Learning with Progress Curiosity</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2305.13396" target="_blank" rel="noopener noreferrer">Developmental Curiosity and Social Interaction in Virtual Agents</a><br>

<h3>Class 4 (Jan 22): Project pitches.
</div>
</div>


<div class="container sec">
<h2>Open-ended learning, adaptation, concept learning</h2>
<h3>Class 5 (Jan 24) Adaptive agents (Student presentation 1)</h3>
<b><a href="https://arxiv.org/abs/2301.07608" target="_blank" rel="noopener noreferrer">Human-Timescale Adaptation in an Open-Ended Task Space</a></b><br>
<b><a href="https://arxiv.org/abs/2307.02276" target="_blank" rel="noopener noreferrer">First-Explore, then Exploit: Meta-Learning Intelligent Exploration
</a></b><br>
Supplementary:<br>
<a href="https://proceedings.mlr.press/v202/schwarzer23a.html" target="_blank" rel="noopener noreferrer">Bigger, Better, Faster: Human-level Atari with human-level efficiency</a><br>
<a href="https://robo-explorer.github.io/" target="_blank" rel="noopener noreferrer">ALAN : Autonomously Exploring Robotic Agents in the Real World
</a><br>
<a href="https://internet-explorer-ssl.github.io/" target="_blank" rel="noopener noreferrer">Internet Explorer: 
Targeted Representation Learning on the Open Web</a><br>
<a href="https://arxiv.org/abs/2310.09971" target="_blank" rel="noopener noreferrer">AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents
</a><br>


<h3>Class 6 (Jan 29): Concept discovery and AI for science (Student presentation 2)</h3>
<b><a href="https://arxiv.org/abs/2310.16410" target="_blank" rel="noopener noreferrer">Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in AlphaZero
</a></b><br>
Supplementary:<br>
<a href="https://developmentalsystems.org/curious-exploration-of-grn-competencies/" target="_blank" rel="noopener noreferrer">AI-driven Automated Discovery Tools Reveal Diverse Behavioral Competencies of Biological Networks</a><br>

<h3>Class 7 (Jan 31): The future of open-ended learning (Student presentation 3)</h3>
<b><a href="https://royalsocietypublishing.org/doi/full/10.1098/rsos.230539" target="_blank" rel="noopener noreferrer">General intelligence requires rethinking exploration
</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2012.09830" target="_blank" rel="noopener noreferrer">Autotelic Agents with Intrinsically Motivated Goal-Conditioned Reinforcement Learning: a Short Survey
</a><br>

</div>

<div class="sechighlight">
<div class="container sec">
<h2>Integrating language -- background</h2>
<h3>Class 8 (Feb 5): Thinking step-by-step (Student presentation 4)</h3>
<b><a href="https://arxiv.org/abs/2308.09687" target="_blank" rel="noopener noreferrer">Graph of Thoughts: Solving Elaborate Problems with Large Language Models</a></b><br>
<b><a href="https://arxiv.org/abs/2305.10601" target="_blank" rel="noopener noreferrer">Tree of Thoughts: Deliberate Problem Solving with Large Language Models</a></b><br>
<b><a href="https://arxiv.org/abs/2201.11903" target="_blank" rel="noopener noreferrer">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></b><br>

<h3>Class 9 (Feb 7) Can LLMs reason, though? (Student presentation 5)</h3>
<b><a href="https://arxiv.org/abs/2310.08118" target="_blank" rel="noopener noreferrer">Can Large Language Models Really Improve by Self-critiquing Their Own Plans?</a></b><br>
<b><a href="https://arxiv.org/abs/2310.12397" target="_blank" rel="noopener noreferrer">GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2310.01798" target="_blank" rel="noopener noreferrer">Large Language Models Cannot Self-Correct Reasoning Yet
</a><br>


<h3>Class 10 (Feb 12) Code for agency? (Instructor lecture)</h3>
<b><a href="https://openreview.net/forum?id=qd9qcbVAwQ" target="_blank" rel="noopener noreferrer">Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions</a></b><br>
<b><a href="https://arxiv.org/abs/2309.05660" target="_blank" rel="noopener noreferrer">Hypothesis Search: Inductive Reasoning with Language Models</a></b><br>

<h3>Class 11 (Feb 14) Project midpoint feedback session.</h3>

</div>
</div>

<div class="container sec">
<h2>Integrating language -- first attempts</h2>

<h3>Class 12 (Feb 21) Language-based agents, 1 (Student presentation 6)</h3>
<b><a href="https://arxiv.org/abs/2307.15818" target="_blank" rel="noopener noreferrer">RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control</a></b><br>
<b><a href="https://arxiv.org/abs/2304.03442" target="_blank" rel="noopener noreferrer">Generative Agents: Interactive Simulacra of Human Behavior</a></b><br>

Supplementary:<br>
<a href="https://allenai.github.io/clin/" target="_blank" rel="noopener noreferrer">CLIN: A Continually Learning Language Agent for Rapid Task Adaptation and Generalization
</a><br>
<a href="https://arxiv.org/abs/2310.02172" target="_blank" rel="noopener noreferrer">Lyfe Agents: Generative agents for low-cost real-time social interactions
</a><br>
<a href="https://dynalang.github.io/" target="_blank" rel="noopener noreferrer">Learning to Model the World with Language</a><br>
<h3>Class 13 (Feb 26) Language-based agents, 2 (Student presentation 7)</h3>
<b><a href="https://arxiv.org/abs/2305.16291" target="_blank" rel="noopener noreferrer">Voyager: An Open-Ended Embodied Agent with Large Language Models</a></b><br>
<b><a href="https://arxiv.org/abs/2305.12487" target="_blank" rel="noopener noreferrer">Augmenting Autotelic Agents with Large Language Models</a></b><br>

Supplementary:<br>
<a href="https://arxiv.org/abs/2302.01560" target="_blank" rel="noopener noreferrer">Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents</a><br>
<a href="https://arxiv.org/abs/2307.14993" target="_blank" rel="noopener noreferrer">Thinker: Learning to Plan and Act
</a><br>


<h3>Class 14 (Feb 28) Language-based agents, 3 (Student presentation 8)</h3>
<b><a href="https://arxiv.org/abs/2303.11366" target="_blank" rel="noopener noreferrer">Reflexion: Language Agents with Verbal Reinforcement Learning
</a></b><br>
<b><a href="https://arxiv.org/abs/2203.14465" target="_blank" rel="noopener noreferrer">STaR: Bootstrapping Reasoning With Reasoning
</a></b><br>

Supplementary:<br>
<a href="https://arxiv.org/abs/2310.02304" target="_blank" rel="noopener noreferrer">Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation</a><br>

<h3>Class 15 (Mar 4) New benchmarks (Student presentation 9)</h3>
<b><a href="https://arxiv.org/abs/2310.03302" target="_blank" rel="noopener noreferrer">Benchmarking Large Language Models As AI Research Agents
</a></b><br>
<b><a href="https://arxiv.org/abs/2310.06770" target="_blank" rel="noopener noreferrer">SWE-bench: Can Language Models Resolve Real-World GitHub Issues?
</a></b><br>

Supplementary:<br>
<a href="https://arxiv.org/abs/2310.06828" target="_blank" rel="noopener noreferrer">RoboHive: A Unified Framework for Robot Learning</a><br>
<a href="https://openreview.net/forum?id=UgPAaEugH3" target="_blank" rel="noopener noreferrer">Gigastep - One Billion Steps per Second Multi-agent Reinforcement Learning</a><br>
<a href="https://arxiv.org/abs/2308.03688" target="_blank" rel="noopener noreferrer">AgentBench: Evaluating LLMs as Agents</a><br>
</div>


<div class="sechighlight">
<div class="container sec">
<h2>Wrap and final presentations</h2>
<h3>Class 16 (Mar 8): Where to from here? Instructor-led synthesis discussion.</h3>
<h3>Class 17 (Mar 13): Final presentations, part 1.</h3>
<h3>Class 18 (Mar 13): Final presentations, part 2.</h3>
</div>
</div>


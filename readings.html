<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Stanford University CS422: Interactive and Embodied Learning</title>

  <!-- bootstrap -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css">

  <!-- Google fonts -->
  <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" type="text/css" href="style.css" />

 </head>

 <div id="header">
  <div class='text-right'><h2><a href="index.html" style="color: black; text-decoration: none;">CS422: Interactive and Embodied Learning</a></h2>
</div>

  <h1>Syllabus and readings</h1>
  <div class='text-center'>
    <p>Required readings in <b>bold</b>; others supplementary. The supplementary lists can get quite long -- this is not meant to be imposing! We simply think that each represents a handy constellation of papers for those interested in getting more acquainted with each subarea. We will provide a roadmap as we go with overviews in class. Feel free to ask for more context at any time.
    </p>

    <p>
      Please see <a href="talk_faq.html">these guidelines</a> for giving a good talk. Every student is responsible for doing all required readings. Please come prepared to discuss, and come being able to describe background, methodology, experimental setups, and key results (for experimental papers). For non-experimental papers, be prepared to discuss the background and each key idea. 

    </p>
  </div>

<div class="sechighlight">
<div class="container sec">
<h2>Framing</h2>
<h3>Class 1 (Jan 9): Conceptual framing, reading and project organization, expectations.</h3>
<h3>Class 2 (Jan 11): An early relevant on curiosity and world model building. Instructor presents as a model for future presentations.</h3>
<b><a href="https://ieeexplore.ieee.org/document/4141061" target="_blank" rel="noopener noreferrer">Intrinsic Motivation Systems for Autonomous Mental Development</a></b><br>
Supplementary:<br>
<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2017.02124/full" target="_blank" rel="noopener noreferrer">A Developmental Approach to Machine Learning?</a><br>
<h3>Class 3 (Jan 18): Benchmarks and representations: an introduction. (Instructor lecture)</h3>
Supplementary:<br>
<a href="https://psycnet.apa.org/fulltext/2017-42390-001.html" target="_blank" rel="noopener noreferrer">From Needs to Goals and Representations: Foundations for a Unified Theory of Motivation, Personality, and Development</a><br>
<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-7687.2007.00569.x" target="_blank" rel="noopener noreferrer">Core Knowledge</a><br>
<h3>Class 4 (Jan 23): Project pitches.
</div>
</div>


<div class="container sec">
<h2>Benchmarks</h2>
<h3>Class 5 (Jan 25) Diverse environments with many tasks. (Student presentation 1)</h3>
<b><a href="https://openreview.net/pdf?id=_8DoIe8G3t" target="_blank" rel="noopener noreferrer">BEHAVIOR-1K: A Benchmark for Embodied AI with 1,000 Everyday Activities and Realistic Simulation</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2108.03332" target="_blank" rel="noopener noreferrer">BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments</a><br>
<a href="https://arxiv.org/abs/2007.04954" target="_blank" rel="noopener noreferrer">ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation</a><br>
<a href="https://arxiv.org/abs/1910.10897" target="_blank" rel="noopener noreferrer">Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning</a><br>
<a href="https://arxiv.org/abs/2107.08170" target="_blank" rel="noopener noreferrer">Megaverse: Simulating Embodied Agents at One Million Experiences per Second</a><br>


<h3>Class 6 (Jan 30): Open-world benchmarks. (Student presentation 2)</h3>
<b><a href="https://arxiv.org/abs/2206.08853" target="_blank" rel="noopener noreferrer">MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2202.10583" target="_blank" rel="noopener noreferrer">MineRL Diamond 2021 Competition: Overview, Results, and Lessons Learned</a><br>
<a href="https://arxiv.org/abs/2109.06780" target="_blank" rel="noopener noreferrer">Benchmarking the Spectrum of Agent Capabilities</a><br>

<h3>Class 7 (Feb 1): Some words of caution about benchmarks. (Student presentation 3)</h3>
<b><a href="https://arxiv.org/abs/2107.07002" target="_blank" rel="noopener noreferrer">The Benchmark Lottery</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/1709.06560" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning that Matters</a><br>
<a href="https://arxiv.org/abs/1604.00289" target="_blank" rel="noopener noreferrer">Building Machines That Learn and Think Like People</a><br>

</div>

<div class="sechighlight">
<div class="container sec">
<h2>Representations</h2>
<h3>Class 8 (Feb 6): Offline reinforcement learning. (Student presentation 4)</h3>
<b><a href="https://arxiv.org/abs/2106.01345" target="_blank" rel="noopener noreferrer">Decision Transformer: Reinforcement Learning via Sequence Modeling</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2005.01643" target="_blank" rel="noopener noreferrer">Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems</a><br>
<a href="https://arxiv.org/abs/2106.02039" target="_blank" rel="noopener noreferrer">Offline Reinforcement Learning as One Big Sequence Modeling Problem</a><br>

<h3>Class 9 (Feb 8) The Dreamer world model. (Student presentation 5)</h3>
<b><a href="https://arxiv.org/abs/1912.01603" target="_blank" rel="noopener noreferrer">Dream to Control: Learning Behaviors by Latent Imagination</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2010.02193" target="_blank" rel="noopener noreferrer">Mastering Atari with Discrete World Models</a><br>
<a href="https://arxiv.org/abs/2206.14176" target="_blank" rel="noopener noreferrer">DayDreamer: World Models for Physical Robot Learning</a><br>
<a href="https://arxiv.org/abs/1803.10122" target="_blank" rel="noopener noreferrer">World Models</a><br>
<a href="https://arxiv.org/abs/1903.00374" target="_blank" rel="noopener noreferrer">Model-Based Reinforcement Learning for Atari</a><br>


<h3>Class 10 (Feb 13) Transformers as world models. (Student presentation 6)</h3>
<b><a href="https://arxiv.org/abs/2209.00588" target="_blank" rel="noopener noreferrer">Transformers are Sample Efficient World Models</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/1911.08265" target="_blank" rel="noopener noreferrer">Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model</a><br>
<a href="https://arxiv.org/abs/2202.09481" target="_blank" rel="noopener noreferrer">Decoupling Representation Learning from Reinforcement Learning</a><br>
<a href="https://arxiv.org/abs/2202.09481" target="_blank" rel="noopener noreferrer">TransDreamer: Reinforcement Learning with Transformer World Models</a><br>
</div>
</div>

<div class="container sec">
<h2>Motivations</h2>
<h3>Class 11 (Feb 15) Synthesis so far and introduction to motivation. (Instructor lecture)</h3>
Supplementary:<br>
<a href="https://www.jair.org/index.php/jair/article/view/13673" target="_blank" rel="noopener noreferrer">Towards Continual Reinforcement Learning: A Review and Perspectives</a><br>
<a href="https://arxiv.org/abs/2012.09830" target="_blank" rel="noopener noreferrer">Autotelic Agents with Intrinsically Motivated Goal-Conditioned Reinforcement Learning: a Short Survey</a><br>
<a href="https://arxiv.org/abs/2009.01791" target="_blank" rel="noopener noreferrer">Action and Perception as Divergence Minimization</a><br>



<h3>Class 12 (Feb 22) Biological motivation motivation. (Student presentation 7)</h3>
<b><a href="https://ieeexplore.ieee.org/document/5471106" target="_blank" rel="noopener noreferrer">Intrinsically Motivated Reinforcement Learning: An Evolutionary Perspective</a></b><br>
Supplementary:<br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4193662/" target="_blank" rel="noopener noreferrer">Information seeking, curiosity and attention: computational and neural mechanisms</a><br>

<h3>Class 13 (Feb 27) Project midpoint feedback session.</h3>

<h3>Class 14 (Mar 1) Intrinsically-motivated world model learning. (Student presentation 8)</h3>
<b><a href="https://arxiv.org/abs/2005.05960" target="_blank" rel="noopener noreferrer">Planning to Explore via Self-Supervised World Models</a></b><br>
Supplementary:<br>
<a href="https://arxiv.org/abs/2102.11271" target="_blank" rel="noopener noreferrer">Reinforcement Learning with Prototypical Representations</a><br>
<a href="https://arxiv.org/abs/2007.00350" target="_blank" rel="noopener noreferrer">Adaptive Procedural Task Generation for Hard-Exploration Problems</a><br>
<a href="https://arxiv.org/abs/1810.12162" target="_blank" rel="noopener noreferrer">Model-Based Active Exploration</a><br>
<a href="https://arxiv.org/abs/1912.05510" target="_blank" rel="noopener noreferrer">SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments</a><br>
<a href="https://arxiv.org/abs/1906.04161" target="_blank" rel="noopener noreferrer">Self-Supervised Exploration via Disagreement</a><br>
<a href="https://arxiv.org/abs/2002.12292" target="_blank" rel="noopener noreferrer">RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments</a><br>
<a href="https://arxiv.org/abs/1802.06070" target="_blank" rel="noopener noreferrer">Diversity is All You Need: Learning Skills without a Reward Function</a><br>
<a href="https://arxiv.org/abs/1808.04355" target="_blank" rel="noopener noreferrer">Large-Scale Study of Curiosity-Driven Learning</a><br>
<a href="https://arxiv.org/abs/1705.05363" target="_blank" rel="noopener noreferrer">Curiosity-driven Exploration by Self-supervised Prediction</a><br>
<a href="https://arxiv.org/abs/1703.01732" target="_blank" rel="noopener noreferrer">Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning</a><br>

<h3>Class 15 (Mar 6) Goal-conditioned world models. (Student presentation 9)</h3>
<b><a href="https://arxiv.org/abs/2110.09514" target="_blank" rel="noopener noreferrer">Discovering and Achieving Goals via World Models</a></b><br>
Supplementary:<br>
<a href="https://proceedings.neurips.cc/paper/2021/hash/69eba34671b3ef1ef38ee85caae6b2a1-Abstract.html" target="_blank" rel="noopener noreferrer">Pretraining Representations for Data-Efficient Reinforcement Learning</a><br>
<a href="https://arxiv.org/abs/1705.06366" target="_blank" rel="noopener noreferrer">Automatic Goal Generation for Reinforcement Learning Agents</a><br>
<a href="https://arxiv.org/abs/1807.04742" target="_blank" rel="noopener noreferrer">Visual Reinforcement Learning with Imagined Goals</a><br>
</div>


<div class="sechighlight">
<div class="container sec">
<h2>Wrap and final presentations</h2>
<h3>Class 16 (Mar 8): Where to from here? Instructor-led synthesis discussion.</h3>
<h3>Class 17 (Mar 13): Final presentations, part 1.</h3>
<h3>Class 18 (Mar 13): Final presentations, part 2.</h3>
</div>
</div>

